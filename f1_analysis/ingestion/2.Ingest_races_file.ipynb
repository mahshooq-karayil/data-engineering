{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bb68855-7c3a-4373-bd1a-15c22677ffb6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Ingest races.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0537e6d7-61b8-4a8b-8b53-4aa86872f895",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text('p_data_source','')\n",
    "v_data_source = dbutils.widgets.get('p_data_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0ec41c7-4ffc-4772-b83b-78d2dc795774",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../includes/configuration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe1e20f0-b3fa-41e9-ac7b-d2656bb92e8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../includes/common_functions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cbcc7da-ac44-4a7f-a07a-34633f489dc3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Step 1 - Read the CSV file using the spark dataframe reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f992555d-ab21-4d03-bfc8-b88be6c27ab8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,IntegerType,StringType,DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12e670b3-8fbd-406d-a847-e1e3264f023f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races_schema = StructType(fields=[StructField(\"raceId\",IntegerType(),False),\n",
    "                                  StructField(\"year\",IntegerType(),True),\n",
    "                                  StructField(\"round\",IntegerType(),True),\n",
    "                                  StructField(\"circuitId\",IntegerType(),True),\n",
    "                                  StructField(\"name\",StringType(),True),\n",
    "                                  StructField(\"date\",DateType(),True),\n",
    "                                  StructField(\"time\",StringType(),True),\n",
    "                                  StructField(\"url\",StringType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd2734b0-dafd-499e-b4ae-3690e8f9772f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races_df = spark.read.csv(f\"{raw_folder_path}/races.csv\",header=True,schema=races_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "904e8055-288e-4b20-a737-745aa2308da7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 2 - Add ingestion date and race_timestamp to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf62ee1e-8df2-49a5-825b-7477472e3bb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp,to_timestamp,col,lit,concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb952b57-4138-4f1c-b20c-1cf1526b4079",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races_with_timestamp_df = races_df.withColumn('ingestion_date',current_timestamp()) \\\n",
    "                                  .withColumn('race_timestamp',to_timestamp(concat(col('date'),lit(' '),col('time')),'yyyy-MM-dd HH:mm:ss')) \\\n",
    "                                  .withColumn('data_source',lit(v_data_source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af3b568-3f2a-455d-948e-d9e3ea189d48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 3 - Select only the columns required and rename as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34998086-c5d9-428f-a8aa-69e43b922704",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races_selected_df = races_with_timestamp_df.select(col('raceId').alias('race_id'),col('year').alias('race_year'),\n",
    "                                                   col('round'),col('circuitId').alias('circuit_id'),\n",
    "                                                   col('name'),col('ingestion_date'),\n",
    "                                                   col('race_timestamp'),col('data_source'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe434f7b-8f96-47d3-a58b-92f478b14979",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 4 - Partition the data by Race Year and write the output to processed container in parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53c5d573-0cbd-4ac3-95ba-87abb053f148",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races_selected_df.write.mode('overwrite').partitionBy('race_year').parquet(f\"{processed_folder_path}/races\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6971ac3-1fb5-44dc-bc92-f4dc7b653227",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit('Success')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 406843573213038,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "2.Ingest_races_file",
   "widgets": {
    "p_data_source": {
     "currentValue": "Ergast API",
     "nuid": "8f2b9695-66cd-4afc-91da-5b5333e07e21",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "p_data_source",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
